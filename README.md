# InterpreTrends

This is the official repo of the paper: [**On Behalf of the Stakeholders: Trends in NLP Model Interpretability in the Era of LLMs**](www,google.com)

written by [**Nitay Calderon**](https://nitaytech.github.io/) and [**Roi Reichart**](https://roireichart.com/)

![Alt text](gitpaper.png?raw=true "Title")


## How to include your paper in our survey?

If you have authored a paper that proposes, employs, or discusses NLP model interpretability methods, we would like to include it in an updated version of our paper. <br>

If you are interested, please fill out this [Google Form](www.google.com).<br>

Please note that we will ask you to provide some details about your work, such as a one-sentence summary of the interpretability method used in your paper, as well as categorizing the method according to the taxonomy proposed in our paper, including paradigm and method properties (see the table above).<br>

Additionally, your paper will be included in our human-annotated dataset, which will be accessible to other researchers (see below).<br>


## Dataset

**We plan to release the dataset upon acceptance of our paper.**

This repository includes our dataset in a `csv` file format, which contains annotations for over 2000 papers. These annotations were generated by an LLM (`Gemini-pro-1.5`) and utilized for the trend analysis discussed in our paper. <br>

Additionally, we provide a human-annotated dataset comprising 100 papers annotated by one of the authors, along with additional papers sourced from responses to the Google Form mentioned above. <br>

We hope that this dataset will serve as a valuable resource for researchers looking to further explore and analyze trends in NLP model interpretability.

